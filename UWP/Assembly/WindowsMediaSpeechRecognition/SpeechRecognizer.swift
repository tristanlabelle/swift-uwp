// Generated by swift-winrt
// swiftlint:disable all

import CWinRT
import WindowsRuntime
import UWP
import struct Foundation.UUID

/// Enables speech recognition with either a default or a custom graphical user interface (GUI).
public final class WindowsMediaSpeechRecognition_SpeechRecognizer: WindowsRuntime.WinRTImport<WindowsMediaSpeechRecognition_SpeechRecognizerProjection>, WindowsFoundation_IClosableProtocol {
    // MARK: IActivationFactory members

    public convenience init() throws {
        self.init(_transferringRef: try Self._iactivationFactory.activateInstance(projection: WindowsMediaSpeechRecognition_SpeechRecognizerProjection.self))
    }

    // MARK: Windows.Media.SpeechRecognition.ISpeechRecognizerFactory members

    public convenience init(_ language: WindowsGlobalization_Language?) throws {
        self.init(_transferringRef: try COM.NullResult.unwrap(Self._ispeechRecognizerFactory.create(language)))
    }

    // MARK: Windows.Media.SpeechRecognition.ISpeechRecognizer members

    /// Gets the collection of constraint objects currently added to the SpeechRecognizer object.
    /// - Returns: A collection of ISpeechRecognitionConstraint objects.
    public var constraints: WindowsFoundationCollections_IVector<WindowsMediaSpeechRecognition_ISpeechRecognitionConstraint?> {
        get throws {
            try COM.NullResult.unwrap(_interop.get_Constraints())
        }
    }

    /// Gets the language used for speech recognition.
    /// - Returns: The language used for speech recognition.
    public var currentLanguage: WindowsGlobalization_Language {
        get throws {
            try COM.NullResult.unwrap(_interop.get_CurrentLanguage())
        }
    }

    /// Gets how long a speech recognizer ignores silence or unrecognizable sounds (babble) and continues listening for speech input.
    /// - Returns: The timeout settings.
    public var timeouts: WindowsMediaSpeechRecognition_SpeechRecognizerTimeouts {
        get throws {
            try COM.NullResult.unwrap(_interop.get_Timeouts())
        }
    }

    /// Gets the UI settings for the RecognizeWithUIAsync method.
    /// - Returns: The UI settings.
    public var uioptions: WindowsMediaSpeechRecognition_SpeechRecognizerUIOptions {
        get throws {
            try COM.NullResult.unwrap(_interop.get_UIOptions())
        }
    }

    /// This event is raised when an audio problem is detected that might affect recognition accuracy.
    public func recognitionQualityDegrading(adding speechRecognitionQualityDegradingHandler: WindowsFoundation_TypedEventHandler<WindowsMediaSpeechRecognition_SpeechRecognizer?, WindowsMediaSpeechRecognition_SpeechRecognitionQualityDegradingEventArgs?>?) throws -> WindowsRuntime.EventRegistration {
        let _token = try _interop.add_RecognitionQualityDegrading(speechRecognitionQualityDegradingHandler)
        return WindowsRuntime.EventRegistration(token: _token, remover: recognitionQualityDegrading)
    }

    public func recognitionQualityDegrading(removing cookie: WindowsRuntime.EventRegistrationToken) throws {
        try _interop.remove_RecognitionQualityDegrading(cookie)
    }

    /// This event is raised when a change occurs to the State property during audio capture.
    public func stateChanged(adding stateChangedHandler: WindowsFoundation_TypedEventHandler<WindowsMediaSpeechRecognition_SpeechRecognizer?, WindowsMediaSpeechRecognition_SpeechRecognizerStateChangedEventArgs?>?) throws -> WindowsRuntime.EventRegistration {
        let _token = try _interop.add_StateChanged(stateChangedHandler)
        return WindowsRuntime.EventRegistration(token: _token, remover: stateChanged)
    }

    public func stateChanged(removing cookie: WindowsRuntime.EventRegistrationToken) throws {
        try _interop.remove_StateChanged(cookie)
    }

    /// Asynchronously compile all constraints specified by the Constraints property.
    /// - Returns: The result of the constraints compilation as a SpeechRecognitionCompilationResult object.
    public func compileConstraintsAsync() throws -> WindowsFoundation_IAsyncOperation<WindowsMediaSpeechRecognition_SpeechRecognitionCompilationResult?> {
        try COM.NullResult.unwrap(_interop.compileConstraintsAsync())
    }

    /// Begins a speech recognition session for a SpeechRecognizer object.
    /// - Returns: The result of the speech recognition session that was initiated by the SpeechRecognizer object.
    public func recognizeAsync() throws -> WindowsFoundation_IAsyncOperation<WindowsMediaSpeechRecognition_SpeechRecognitionResult?> {
        try COM.NullResult.unwrap(_interop.recognizeAsync())
    }

    /// Asynchronously starts a speech recognition session that includes additional UI mechanisms, including prompts, examples, text-to-speech (TTS), and confirmations.
    /// - Returns: The result of the speech recognition session as a SpeechRecognitionResult object.
    public func recognizeWithUIAsync() throws -> WindowsFoundation_IAsyncOperation<WindowsMediaSpeechRecognition_SpeechRecognitionResult?> {
        try COM.NullResult.unwrap(_interop.recognizeWithUIAsync())
    }

    // MARK: Windows.Foundation.IClosable members

    /// Disposes the speech recognizer by freeing, releasing, or resetting allocated resources.
    public func close() throws {
        try _iclosable.close()
    }

    // MARK: Windows.Media.SpeechRecognition.ISpeechRecognizer2 members

    /// Gets the continuous recognition session object (SpeechContinuousRecognitionSession ) associated with this SpeechRecognizer.
    /// - Returns: The continuous recognition session object associated with this SpeechRecognizer.
    public var continuousRecognitionSession: WindowsMediaSpeechRecognition_SpeechContinuousRecognitionSession {
        get throws {
            try COM.NullResult.unwrap(_ispeechRecognizer2.get_ContinuousRecognitionSession())
        }
    }

    /// Gets the state of the speech recognizer.
    /// - Returns: The speech recognizer state.
    public var state: WindowsMediaSpeechRecognition_SpeechRecognizerState {
        get throws {
            try _ispeechRecognizer2.get_State()
        }
    }

    /// Occurs during an ongoing dictation session when a recognition result fragment is returned by the speech recognizer.
    public func hypothesisGenerated(adding value: WindowsFoundation_TypedEventHandler<WindowsMediaSpeechRecognition_SpeechRecognizer?, WindowsMediaSpeechRecognition_SpeechRecognitionHypothesisGeneratedEventArgs?>?) throws -> WindowsRuntime.EventRegistration {
        let _token = try _ispeechRecognizer2.add_HypothesisGenerated(value)
        return WindowsRuntime.EventRegistration(token: _token, remover: hypothesisGenerated)
    }

    public func hypothesisGenerated(removing value: WindowsRuntime.EventRegistrationToken) throws {
        try _ispeechRecognizer2.remove_HypothesisGenerated(value)
    }

    /// Asynchronously ends the speech recognition session.
    /// - Returns: No object or value is returned when this method completes.
    public func stopRecognitionAsync() throws -> WindowsFoundation_IAsyncAction {
        try COM.NullResult.unwrap(_ispeechRecognizer2.stopRecognitionAsync())
    }

    // MARK: Windows.Media.SpeechRecognition.ISpeechRecognizerStatics members

    /// Gets the collection of languages supported by the custom grammars of the SpeechRecognitionGrammarFileConstraint and SpeechRecognitionListConstraint objects specified in the Constraints property.
    /// - Returns: The collection of grammar languages.
    public static var supportedGrammarLanguages: WindowsFoundationCollections_IVectorView<WindowsGlobalization_Language?> {
        get throws {
            try COM.NullResult.unwrap(_ispeechRecognizerStatics.get_SupportedGrammarLanguages())
        }
    }

    /// Gets the collection of languages supported by the pre-defined, web-service grammars of the SpeechRecognitionTopicConstraint objects specified in the Constraints property.
    /// - Returns: The collection of languages supported by the pre-defined, web-service grammars.
    public static var supportedTopicLanguages: WindowsFoundationCollections_IVectorView<WindowsGlobalization_Language?> {
        get throws {
            try COM.NullResult.unwrap(_ispeechRecognizerStatics.get_SupportedTopicLanguages())
        }
    }

    /// Gets the speech language of the device specified in **Settings > Time & Language > Speech**.
    /// - Returns: The speech language of the device, or null if a speech language is not installed.
    public static var systemSpeechLanguage: WindowsGlobalization_Language {
        get throws {
            try COM.NullResult.unwrap(_ispeechRecognizerStatics.get_SystemSpeechLanguage())
        }
    }

    // MARK: Windows.Media.SpeechRecognition.ISpeechRecognizerStatics2 members

    /// Asynchronously attempts to set the system language used for speech recognition on an IoT device.
    /// - Parameter speechLanguage: The  BCP-47 -based system language used for speech recognition.
    /// - Returns: An asynchronous operation that returns true if the set operation was a success. Otherwise, returns false.
    public static func trySetSystemSpeechLanguageAsync(_ speechLanguage: WindowsGlobalization_Language?) throws -> WindowsFoundation_IAsyncOperation<Swift.Bool> {
        try COM.NullResult.unwrap(_ispeechRecognizerStatics2.trySetSystemSpeechLanguageAsync(speechLanguage))
    }

    // MARK: Implementation details

    private var _iclosable_storage: COM.COMInterop<CWinRT.SWRT_WindowsFoundation_IClosable>? = nil

    internal var _iclosable: COM.COMInterop<CWinRT.SWRT_WindowsFoundation_IClosable> {
        get throws {
            try _iclosable_storage.lazyInit {
                try _queryInterfacePointer(CWinRT.SWRT_WindowsFoundation_IClosable.iid).cast(to: CWinRT.SWRT_WindowsFoundation_IClosable.self)
            }
        }
    }

    private var _ispeechRecognizer2_storage: COM.COMInterop<CWinRT.SWRT_WindowsMediaSpeechRecognition_ISpeechRecognizer2>? = nil

    internal var _ispeechRecognizer2: COM.COMInterop<CWinRT.SWRT_WindowsMediaSpeechRecognition_ISpeechRecognizer2> {
        get throws {
            try _ispeechRecognizer2_storage.lazyInit {
                try _queryInterfacePointer(CWinRT.SWRT_WindowsMediaSpeechRecognition_ISpeechRecognizer2.iid).cast(to: CWinRT.SWRT_WindowsMediaSpeechRecognition_ISpeechRecognizer2.self)
            }
        }
    }

    deinit {
        _iclosable_storage?.release()
        _ispeechRecognizer2_storage?.release()
    }

    private static var _iactivationFactory_storage: COM.COMInterop<CWinRT.SWRT_IActivationFactory>? = nil

    internal static var _iactivationFactory: COM.COMInterop<CWinRT.SWRT_IActivationFactory> {
        get throws {
            try _iactivationFactory_storage.lazyInit {
                try WindowsRuntime.getActivationFactoryPointer(activatableId: "Windows.Media.SpeechRecognition.SpeechRecognizer", id: CWinRT.SWRT_IActivationFactory.iid)
            }
        }
    }

    private static var _ispeechRecognizerFactory_storage: COM.COMInterop<CWinRT.SWRT_WindowsMediaSpeechRecognition_ISpeechRecognizerFactory>? = nil

    internal static var _ispeechRecognizerFactory: COM.COMInterop<CWinRT.SWRT_WindowsMediaSpeechRecognition_ISpeechRecognizerFactory> {
        get throws {
            try _ispeechRecognizerFactory_storage.lazyInit {
                try WindowsRuntime.getActivationFactoryPointer(activatableId: "Windows.Media.SpeechRecognition.SpeechRecognizer", id: CWinRT.SWRT_WindowsMediaSpeechRecognition_ISpeechRecognizerFactory.iid)
            }
        }
    }

    private static var _ispeechRecognizerStatics_storage: COM.COMInterop<CWinRT.SWRT_WindowsMediaSpeechRecognition_ISpeechRecognizerStatics>? = nil

    internal static var _ispeechRecognizerStatics: COM.COMInterop<CWinRT.SWRT_WindowsMediaSpeechRecognition_ISpeechRecognizerStatics> {
        get throws {
            try _ispeechRecognizerStatics_storage.lazyInit {
                try WindowsRuntime.getActivationFactoryPointer(activatableId: "Windows.Media.SpeechRecognition.SpeechRecognizer", id: CWinRT.SWRT_WindowsMediaSpeechRecognition_ISpeechRecognizerStatics.iid)
            }
        }
    }

    private static var _ispeechRecognizerStatics2_storage: COM.COMInterop<CWinRT.SWRT_WindowsMediaSpeechRecognition_ISpeechRecognizerStatics2>? = nil

    internal static var _ispeechRecognizerStatics2: COM.COMInterop<CWinRT.SWRT_WindowsMediaSpeechRecognition_ISpeechRecognizerStatics2> {
        get throws {
            try _ispeechRecognizerStatics2_storage.lazyInit {
                try WindowsRuntime.getActivationFactoryPointer(activatableId: "Windows.Media.SpeechRecognition.SpeechRecognizer", id: CWinRT.SWRT_WindowsMediaSpeechRecognition_ISpeechRecognizerStatics2.iid)
            }
        }
    }
}